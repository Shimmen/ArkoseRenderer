#version 460

#include <common/brdf.glsl>
#include <common/namedUniforms.glsl>
#include <common/spherical.glsl>
#include <common/rayTracing.glsl>
#include <ddgi/common.glsl>
#include <ddgi/probeSampling.glsl>
#include <shared/CameraState.h>

layout(set = 0, binding = 0) uniform AccelerationStructure topLevelAS;
layout(set = 0, binding = 1) uniform CameraStateBlock { CameraState camera; };
layout(set = 0, binding = 2) uniform sampler2D environmentMap;
layout(set = 0, binding = 3, rgba16f) uniform image2D surfelImage;

layout(set = 4, binding = 0) uniform DDGIGridDataBlock { DDGIProbeGridData probeGridData; };
layout(set = 4, binding = 1) uniform sampler2D ddgiIrradianceAtlas;
layout(set = 4, binding = 2) uniform sampler2D ddgiVisibilityAtlas;

NAMED_UNIFORMS_STRUCT(RayTracingPushConstants, pushConstants)

layout(location = 0) rayPayload RayPayload payload;

struct HitResult {
    bool didHit;
    vec3 color;
    float dist;
    vec3 baseColor;
    vec3 normal;
    float metallic;
    float roughness;
};

HitResult tracePrimaryRay(vec3 origin, vec3 direction)
{
    float tmin = camera.zNear;
    float tmax = camera.zFar;

    int numHits = 0;
    vec3 color = vec3(0.0);

    // Opaque
    {
        uint rayFlags = RayFlags_Opaque | RayFlags_CullBackFacingTriangles;
        uint cullMask = RT_HIT_MASK_OPAQUE;

        traceRay(topLevelAS, rayFlags, cullMask, 0, 0, 0, origin, tmin, direction, tmax, 0);
        if (payload.hitT != HIT_T_MISS) {
            tmax = payload.hitT;
            color = payload.color;
            numHits += 1;
        }
    }

    // Masked (todo: also include alpha-translucents here, but treat them like masked)
    {
        uint rayFlags = RayFlags_NoOpaque;
        uint cullMask = RT_HIT_MASK_MASKED;

        traceRay(topLevelAS, rayFlags, cullMask, 0, 0, 0, origin, tmin, direction, tmax, 0);
        if (payload.hitT != HIT_T_MISS) {
            tmax = payload.hitT;
            color = payload.color;
            numHits += 1;
        }
    }

    // Draw environment if miss
    if (numHits == 0) {
        // TODO: Consider if we really want to use the very large value camera.zFar here or if we should use some smaller "large" value for sky hits.
        // For the purpose of the Chebychev-test we do want to record a large variance of course, but we need some numerical stability still.. 
        // We should never need to see anything beyond the grid cell distance diagonal, so maybe just set it to that (plus epsilon)? Would that work?
        tmax = camera.zFar; // if miss, use camera far distance as hit distance

        vec2 sampleUv = sphericalUvFromDirection(direction);
        color = pushConstants.environmentMultiplier * texture(environmentMap, sampleUv).rgb;
    }

    HitResult result;
    result.color = color;
    result.dist = tmax;
    result.didHit = numHits > 0;
    if (numHits > 0) {
        result.baseColor = payload.baseColor;
        result.normal = payload.normal;
        result.metallic = payload.metallic;
        result.roughness = payload.roughness;
    }
    return result;
}

vec3 evaluateIndirectLightFromPreviousFrame(vec3 P, vec3 V, vec3 N, vec3 baseColor, float metallic)
{
    // For diffuse, simply pretend half vector is normal
    vec3 H = N;

    vec3 F0 = mix(vec3(DIELECTRIC_REFLECTANCE), baseColor, metallic);
    vec3 F = F_Schlick(max(0.0, dot(V, H)), F0);

    vec3 irradiance = sampleDynamicDiffuseGlobalIllumination(P, N, probeGridData, ddgiIrradianceAtlas, ddgiVisibilityAtlas);
    vec3 indirectDiffuse = vec3(1.0 - metallic) * vec3(1.0 - F) * irradiance;

    return indirectDiffuse;
}

void main()
{
    ivec2 targetPixel = ivec2(rt_LaunchID.xy);

    // TODO: We're "supposed" to report *negative* ray distance when we hit a backface, so that we can optimize probe offsets! We're not doing that yet though.
    //    see gl_HitKindFrontFacingTriangleNV & gl_HitKindBackFacingTriangleNV

    uint probeIdx = rt_LaunchID.x;
    uint sampleIdx = rt_LaunchID.y;
    uint sampleCount = imageSize(surfelImage).y;

    vec3 probePosition = calculateProbePosition(probeGridData, probeIdx);
    vec3 sampleDirection = calculateRotatedSphericalFibonacciSample(probeIdx, sampleIdx, sampleCount, pushConstants.frameIdx);
    HitResult hit = tracePrimaryRay(probePosition, sampleDirection);

    vec3 color = hit.color;

    if (hit.didHit) {
        vec3 hitPos = probePosition + hit.dist * sampleDirection;

        // TODO: This seems way too dark..? Almost no difference to having only a single bounce

        color += hit.color * evaluateIndirectLightFromPreviousFrame(hitPos, -sampleDirection, hit.normal, hit.baseColor, hit.metallic);
        //color += vec3(0.2) * evaluateIndirectLightFromPreviousFrame(hitPos, -sampleDirection, hit.normal, hit.baseColor, hit.metallic);
    }

    imageStore(surfelImage, targetPixel, vec4(color, hit.dist));

    //////////////////////////

#if 0 // for debugging the ray tracing code and displaying it on a texture instead of rendering into the probes

    const vec2 pixelCenter = vec2(rt_LaunchID.xy) + vec2(0.5);
    const vec2 inUV = pixelCenter / vec2(rt_LaunchSize.xy);
    vec2 d = inUV * 2.0 - 1.0;

    vec4 origin = camera.worldFromView * vec4(0, 0, 0, 1);
    vec4 target = camera.viewFromProjection * vec4(d.x, d.y, 1.0, 1.0);
    vec4 direction = camera.worldFromView * vec4(normalize(target.xyz / target.w), 0.0);

    HitResult result = tracePrimaryRay(origin.xyz, direction.xyz);
    imageStore(surfelImage, targetPixel, vec4(result.color, 0.0));

#endif
}
