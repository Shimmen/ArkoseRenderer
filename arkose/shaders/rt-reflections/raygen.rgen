#version 460

#include <common.glsl>
#include <common/brdf.glsl>
#include <common/encoding.glsl>
#include <common/namedUniforms.glsl>
#include <common/spherical.glsl>
#include <rayTracing/common/common.glsl>
#include <shared/CameraState.h>

layout(set = 0, binding = 0) uniform AccelerationStructure topLevelAS;
layout(set = 0, binding = 1) uniform CameraStateBlock { CameraState camera; };
layout(set = 0, binding = 2, rgba16f) uniform writeonly image2D resultImage;
layout(set = 0, binding = 3, rgba16f) uniform writeonly image2D reflectionDirectionImg;
layout(set = 0, binding = 4) uniform sampler2D sceneMaterialTex;
layout(set = 0, binding = 5) uniform sampler2D sceneNormalTex;
layout(set = 0, binding = 6) uniform sampler2D sceneDepthTex;
layout(set = 0, binding = 7) uniform sampler2D environmentTex;
layout(set = 0, binding = 8) uniform sampler2DArray blueNoiseTexture;

#if WITH_DDGI
#include <ddgi/probeSampling.glsl>
layout(set = 4, binding = 0) uniform DDGIGridDataBlock { DDGIProbeGridData ddgiProbeGridData; };
layout(set = 4, binding = 1) buffer ProbeOffsetBlock { vec3 probeOffsets[]; };
layout(set = 4, binding = 2) uniform sampler2D ddgiIrradianceAtlas;
layout(set = 4, binding = 3) uniform sampler2D ddgiVisibilityAtlas;
#endif

NAMED_UNIFORMS_STRUCT(RayTracingPushConstants, constants);
float mirrorRoughnessThreshold() { return constants.parameter1; }
float noTracingRoughnessThreshold() { return constants.parameter2; }
float blueNoiseArrayLayerIndexForFrame() { return constants.parameter3; }

mat3 createIsotropicTBN(vec3 N)
{
	// Pick abitrary tangent that is orthogonal to the normal
	vec3 T;
	if (abs(N.z) > 0.0) {
		float k = sqrt(N.y * N.y + N.z * N.z);
		T = vec3(0.0, -N.z / k, N.y / k);
	} else {
		float k = sqrt(N.x * N.x + N.y * N.y);
		T = vec3(N.y / k, -N.x / k, 0.0);
	}

	vec3 B = cross(N, T);

	mat3 TBN = mat3(T, B, N);
	return transpose(TBN);
}

layout(location = 0) rayPayload RayPayloadMain payload;

void main()
{
	const ivec2 pixelCoord = ivec2(rt_LaunchID.xy);
	const vec2 pixelCenter = vec2(pixelCoord) + vec2(0.5);
	const vec2 inUV = pixelCenter / vec2(rt_LaunchSize.xy);

	float nonLinearDepth = texelFetch(sceneDepthTex, pixelCoord, 0).r;
	if (nonLinearDepth >= 1.0 - 1e-6) {
		imageStore(resultImage, pixelCoord, vec4(0.0));
		return;
	}

	vec4 materialProps = texelFetch(sceneMaterialTex, pixelCoord, 0).rgba;
	float roughness = materialProps.r; // Includes clearcoat roughness if present!
	float metallic = materialProps.g;

	if (roughness >= noTracingRoughnessThreshold()) {
		// TODO: Maybe just early return if all lanes agree on this, otherwise trace anyway
		// (although, would add more noise to the image overall)
		imageStore(resultImage, pixelCoord, vec4(0, 0, 0, 0));
		imageStore(reflectionDirectionImg, pixelCoord, vec4(0, 0, 0, 0));
		return;
	}

	vec3 viewSpaceNormal = decodeNormal(texelFetch(sceneNormalTex, pixelCoord, 0).rg);
	vec3 N = mat3(camera.worldFromView) * viewSpaceNormal;

	vec4 cameraOrigin = camera.worldFromView * vec4(0, 0, 0, 1);
	vec4 cameraTarget = camera.worldFromView * camera.viewFromProjection * vec4(inUV * 2.0 - 1.0, nonLinearDepth, 1.0);
	cameraTarget.xyz /= cameraTarget.w;

	vec3 rayOrigin = cameraTarget.xyz;
	vec3 viewRay = normalize(cameraTarget.xyz - cameraOrigin.xyz);

	vec3 lookupCoord = vec3(pixelCenter / vec2(textureSize(blueNoiseTexture, 0).xy), blueNoiseArrayLayerIndexForFrame());
	vec2 randomness = textureLod(blueNoiseTexture, lookupCoord, 0.0).xy;

	mat3 TBN = createIsotropicTBN(N);
	mat3 inverseTBN = transpose(TBN); // rotation only

	// In tangent space!
	vec3 viewDirection = TBN * (-viewRay);
	vec3 sampledNormal = sampleSpecularBRDF(viewDirection, roughness, randomness);
	vec3 reflectedDirection = reflect(-viewDirection, sampledNormal);

	// Transform back to world space
	vec3 rayDirection = inverseTBN * reflectedDirection;

	float tmin = 0.01;
	float tmax = 10000.0;

	int numHits = 0;
	vec3 reflectedRadiance = vec3(0.0);

	// Opaque
	{
		uint rayFlags = RayFlags_Opaque;
		uint cullMask = RT_HIT_MASK_OPAQUE;

		traceRay(topLevelAS, rayFlags, cullMask, 0, 0, 0, rayOrigin, tmin, rayDirection, tmax, 0);
		if (payload.hitT <= tmax) {
			tmax = payload.hitT;
			reflectedRadiance = payload.color;
			numHits += 1;
		}
	}

	// Add indirect diffuse contribution to hits
	#if WITH_DDGI
	if (numHits > 0) {

		const vec3 P = rayOrigin + payload.hitT * rayDirection;
		const vec3 N = payload.normal;
		const vec3 V = -rayDirection;

		#if 1

			// Pretend that even fully metallic objects are slightly diffuse, so that they get some DDGI contribution and don't appear fully black
			// when seen in/through reflections. This is a hack but it looks nice and is cheaper than e.g. tracing another ray to resolve color.
			// Also, use dielectric F0 and no view-dependent F, as we simply pretend that the diffuse light is our reflected light here.
			float hitMetallic = min(payload.metallic, 0.6);
			const vec3 F0 = vec3(DIELECTRIC_REFLECTANCE);
			const vec3 F = F0;
			
		#else

			// For diffuse, simply pretend half vector is normal (same trick as for the split sum approximation)
			vec3 H = payload.normal;

			float hitMetallic = min(payload.metallic, 0.5);
			const vec3 F0 = mix(vec3(DIELECTRIC_REFLECTANCE), payload.baseColor, hitMetallic);
			const vec3 F = F_Schlick(max(0.0, dot(V, H)), F0);
			
		#endif

		vec3 irradiance = sampleDynamicDiffuseGlobalIllumination(P, N, V, ddgiProbeGridData, ddgiIrradianceAtlas, ddgiVisibilityAtlas);
		vec3 indirectDiffuse = vec3(1.0 - hitMetallic) * vec3(1.0 - F) * irradiance;
		reflectedRadiance += payload.baseColor * indirectDiffuse;
	}
	#endif

	// Draw environment if miss
	if (numHits == 0) {
		vec2 sampleUv = sphericalUvFromDirection(rayDirection);
		reflectedRadiance = constants.environmentMultiplier * texture(environmentTex, sampleUv).rgb;
	}

	// Need distance from reflection point to hit point for denoiser
	float rayLength = tmax;

	imageStore(resultImage, pixelCoord, vec4(reflectedRadiance, rayLength));
	imageStore(reflectionDirectionImg, pixelCoord, vec4(rayDirection, 0.0));
}
